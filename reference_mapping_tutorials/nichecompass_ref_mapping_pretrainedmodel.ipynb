{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3620c1e1-33ca-4716-b812-e77d62b1d71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A full tutorial is available here:\n",
    "https://nichecompass.readthedocs.io/en/latest/tutorials/notebooks/mouse_cns_spatial_reference_mapping.html\n",
    "\n",
    "Here we illustrate use of our core dataset as a reference for mapping the validation data\n",
    "\n",
    "There are two major things to do:\n",
    "1. set up a working nichecompass env  (see https://github.com/Lotfollahi-lab/nichecompass)\n",
    "2. set path for where to save\n",
    "3. create a list with sample ids of xenium-5k sections to query \n",
    "(reference_batches are defined as our data, to contextualise future results)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623a9c89-3f58-4a77-9cf9-7dc76f443e7c",
   "metadata": {},
   "source": [
    "# Set up working environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b206f847-6615-4741-8df5-5581110da775",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://github.com/Lotfollahi-lab/nichecompass\n",
    "here we use version 0.3.0\n",
    "\"\"\"\n",
    "\n",
    "import os, sys\n",
    "import random\n",
    "import warnings\n",
    "import logging\n",
    "from datetime import datetime\n",
    "# import gdown\n",
    "\n",
    "import anndata as ad\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sp\n",
    "import seaborn as sns\n",
    "import squidpy as sq\n",
    "from matplotlib import gridspec\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from re import sub\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from nichecompass.models import NicheCompass\n",
    "from nichecompass.utils import (add_gps_from_gp_dict_to_adata,\n",
    "                                create_new_color_dict,\n",
    "                                compute_communication_gp_network,\n",
    "                                visualize_communication_gp_network,\n",
    "                                extract_gp_dict_from_mebocost_ms_interactions,\n",
    "                                #extract_gp_dict_from_mebocost_es_interactions,\n",
    "                                extract_gp_dict_from_nichenet_lrt_interactions,\n",
    "                                extract_gp_dict_from_omnipath_lr_interactions,\n",
    "                                #filter_and_combine_gp_dict_gps,\n",
    "                                filter_and_combine_gp_dict_gps_v2,\n",
    "                                generate_enriched_gp_info_plots)\n",
    "\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988ecf90-f1e3-4cec-91dd-198ccc349b4a",
   "metadata": {},
   "source": [
    "# Path to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac38aad-dc20-46b1-9470-c8348f579d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "make sure inside this path, you have the folders gene_annotations \n",
    "and gene_programs with the files\n",
    "(available from https://github.com/Lotfollahi-lab/nichecompass/tree/main/data)\n",
    "\n",
    "outputs also save here\n",
    "\"\"\"\n",
    "\n",
    "handle='/lustre/scratch124/cellgen/haniffa/projects/developmental_fibroblasts/nobackup_output/nichecompasss/nichecompass/' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078f4bbb-a833-4bea-91ac-67bbc3342197",
   "metadata": {},
   "source": [
    "# Which batches to query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dfcf28-28be-42ae-b6c0-28d17dfc4864",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "load adata (includes reference and query)\n",
    "- note that sample id is in adata.obs[\"sample\"]\n",
    "- cell type is in adata.obs[\"Annotation\"]\n",
    "\n",
    "if using our adata as reference, then either:\n",
    "1. remove all query samples (in query_batches below), or\n",
    "2. add query samples to reference_batches \n",
    "\n",
    "and then add your sample id's to query_batches (i.e. need to concat your adata)\n",
    "\"\"\"\n",
    "\n",
    "ADATA_PATH= '/lustre/scratch126/cellgen/lotfollahi/ls34/nemo/adata_all.h5ad.clustered.clustered10.good.prenichecompass'\n",
    "#'/nfs/team298/ls34/xenium_atlas/model_ALL_CLEAN_scanvi_ALL/adata_counts_integrated_final_colored.h5ad'\n",
    "\n",
    "adata_vis=sc.read_h5ad(ADATA_PATH)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574c1b9a-804d-44c4-895b-4347046166b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "SELECT BATCHES TO QUERY\n",
    "\"\"\"\n",
    "\n",
    "query_batches = ['BK21-SKI-27-FO-1-S8-A3',\n",
    " 'BK51-SKI-27-FO-2-S9-B2',\n",
    " 'BK23-SKI-27-FO-1-S8-B1',\n",
    " 'BK21-SKI-27-FO1-S11-C1',\n",
    " 'BK27-SKI-27-FO-5-S9-D1',\n",
    " 'CE3-SKI-28-FO-1-S25-E1',\n",
    " 'BK21-SKI-27-FO-1-S13-C2',\n",
    " 'BK22-SKI-27-FO-2-S7-A1',\n",
    " 'BK30-SKI-28-FO-1-S6-B2',\n",
    " 'BK39-SKI-27-FO-1-S8-D2',\n",
    " 'CE3-SKI-28-FO-1-S25-D1',\n",
    " 'BK30-SKI-28-FO-1-S14-C2',\n",
    " 'BK27-SKI-27-FO-1-S6-C1',\n",
    " 'CE4-SKI-27-FO-1-S25-S29-S32',\n",
    " 'BK51-SKI-27-FO-2-S4-S8-S6',\n",
    " 'BK23-SKI-27-FO-5-S9-A2',\n",
    " 'CE3-SKI-28-FO-1-S28-D2']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cc743a-f01d-4b2a-a8b2-c84af2bda4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "OUR REFERENCE DATA\n",
    "\"\"\"\n",
    "reference_batches =  ['Week 8 (resolved)_CE3-SKI-28-FO-4-S22-E1_a',\n",
    " 'Lesional_CE5-SKI-28-FO-1-S22_replicate',\n",
    " 'Week 8 (resolved)_CE3-SKI-28-FO-4-S22-E1_b',\n",
    " 'BK39_Non-lesional Baseline',\n",
    " 'Baseline_resolved_CE3-SKI-28-FO-1-S22-B1',\n",
    " 'Week 8 (resolved)_CE5-SKI-27-FO-4-S22-E1',\n",
    " 'BK23_Lesional Baseline',\n",
    " '3D_BK25_week12-D2',\n",
    " '3D_BK25_week12-D1orE1b',\n",
    " 'Baseline_never_CE5-SKI-27-FO-2-S22_replicate',\n",
    " '3D_BK22_Lesional_baseline-C2',\n",
    " 'BK51_Never Lesional',\n",
    " 'BK20_Week 12',\n",
    " 'BK30_Lesional Baseline',\n",
    " '3D_BK22_Lesional_baseline-A1',\n",
    " 'Week 8 (resolved)_CE4-SKI-27-FO-3-S22-E2_b',\n",
    " 'BK30_Week 12',\n",
    " '3D_BK22_Lesional_baseline-B1',\n",
    " 'Lesional_Baseline_resolved_CE3-SKI-24-FO-1-S22_replicate',\n",
    " 'Baseline_resolved_CE6-SKI-20-FO-1-S22-C2',\n",
    " 'Baseline_never_CE5-SKI-27-FO-2-S22-C1',\n",
    " 'BK49_wk8 Relapse',\n",
    " 'Week 8 (resolved)_CE3-SKI-28-FO-4-S22_replicate',\n",
    " 'BK21_Non-lesional Baseline',\n",
    " 'BK18_Week 12',\n",
    " 'BK24_Week 12',\n",
    " 'Baseline_never_CE3-SKI-28-FO-2-S22_replicate',\n",
    " '3D_BK25_week12-B2',\n",
    " 'BK39_Week 12',\n",
    " 'BK22_Non-lesional Baseline',\n",
    " 'BK27_Week 12',\n",
    " 'Baseline_resolved_CE4-SKI-27-FO-1-S22-B2',\n",
    " 'Baseline_resolved_CE6-SKI-20-FO-1-S22_replicate',\n",
    " 'BK49_Past Lesional',\n",
    " 'BK18_Non-lesional Baseline',\n",
    " '3D_BK22_Lesional_baseline-D1',\n",
    " 'BK27_Lesional Baseline',\n",
    " 'Baseline_resolved_CE6-SKI-28-FO-4-S22_replicate',\n",
    " 'BK25_Lesional Baseline',\n",
    " 'BK25_Week 12',\n",
    " 'Lesional_CE6-SKI-28-FO-4-S22_replicate',\n",
    " 'Baseline_resolved_CE4-SKI-27-FO-1-S22_replicate',\n",
    " 'BK50_Never Lesional',\n",
    " 'BK51_Past Lesional',\n",
    " 'Baseline_resolved_CE5-SKI-27-FO-1-S22_replicate',\n",
    " 'BK24_Non-lesional Baseline',\n",
    " 'BK50_Past Lesional',\n",
    " 'BK39_Lesional Baseline',\n",
    " 'Lesional_CE5-SKI-28-FO-1-S22-A1',\n",
    " '3D_BK22_Lesional_baseline-B2',\n",
    " 'BK25_Non-lesional Baseline',\n",
    " 'BK20_Non-lesional Baseline',\n",
    " '3D_BK25_week12-D1orE1a',\n",
    " 'Baseline_resolved_CE5-SKI-27-FO-1-S22-B1',\n",
    " '3D_BK25_week12-C1',\n",
    " 'Week 8 (resolved)_CE6-SKI-28-FO-3-S22_replicate',\n",
    " 'BK30_Day 14',\n",
    " '3D_BK22_Lesional_baseline-A2',\n",
    " 'Week 8 (resolved)_CE6-SKI-28-FO-3-S22-E2',\n",
    " 'BK18_Lesional Baseline',\n",
    " 'Baseline_resolved_CE3-SKI-28-FO-1-S22_replicate',\n",
    " 'Lesional_CE4-SKI-27-FO-4-S22-A2',\n",
    " 'BK24_Lesional Baseline',\n",
    " 'Baseline_never_CE4-SKI-21-FO-1-S22_replicate',\n",
    " 'BK43_Never Lesional',\n",
    " 'BK22_Lesional Baseline',\n",
    " '3D_BK25_week12-A2',\n",
    " 'BK22_Week 12',\n",
    " 'Week 8 (resolved)_CE4-SKI-27-FO-3-S22_replicate',\n",
    " 'BK51_wk8 Relapse',\n",
    " 'BK23_Non-lesional Baseline',\n",
    " 'BK27_Non-lesional Baseline',\n",
    " 'Week 8 (resolved)_CE4-SKI-27-FO-3-S22-E2_a',\n",
    " 'Lesional_CE4-SKI-27-FO-4-S22_replicate',\n",
    " 'Baseline_never_CE3-SKI-28-FO-2-S22-C1',\n",
    " 'BK46_Never Lesional',\n",
    " 'BK30_Non-lesional Baseline',\n",
    " 'BK21_Week 12',\n",
    " 'BK43_Past Lesional',\n",
    " 'Week 8 (resolved)_CE5-SKI-27-FO-4-S22_replicate',\n",
    " 'BK21_Lesional Baseline',\n",
    " 'BK46_Past Lesional',\n",
    " '3D_BK25_week12-B1',\n",
    " 'BK20_Lesional Baseline',\n",
    " 'BK51_Past Lesional wk8 relaspe',\n",
    " 'Baseline_never_CE4-SKI-21-FO-1-S22-C2',\n",
    " '3D_BK22_Lesional_baseline-D2',\n",
    " 'Lesional_CE6-SKI-28-FO-4-S22-A1',\n",
    " 'BK49_Past Lesional wk8 relaspe',\n",
    " 'Baseline_resolved_CE6-SKI-28-FO-1-S22-B2',\n",
    " '3D_BK25_week12-C2',\n",
    " '3D_BK25_week12-A1',\n",
    " 'Lesional_CE3-SKI-24-FO-1-S22-A1',\n",
    " 'BK23_Week 12',\n",
    " 'BK49_Never Lesional']\n",
    "\n",
    "for x in query_batches:\n",
    "    if x not in adata_vis.obs[\"sample\"].unique():\n",
    "        raise ValueError(f\"Sample '{x}' not found in adata.obs['sample']\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a0e757-1bce-4666-9531-d1a394b9e791",
   "metadata": {},
   "source": [
    "# The below steps we run as a job, so we will skip here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45d25cb8-00fe-460a-af7d-7792c227753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "n_svg = 3000\n",
    "n_epochs = 100\n",
    " \n",
    "### Dataset ###\n",
    "n_neighbors = 8\n",
    "n_sampled_neighbors = 4\n",
    "\n",
    "species = \"human\" # assume human as reference is human skin\n",
    "\n",
    "spatial_key = \"spatial\"\n",
    "mapping_entity_key = \"mapping_entity\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076e3ed3-5434-41a7-b483-489d910b776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = f\"XeniumTUTORIAL_{n_svg}svg_n{n_neighbors}_REFQ\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ece513-f5cb-450c-8e88-c539592b14af",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model ###\n",
    "# AnnData keys\n",
    "counts_key = \"counts\"\n",
    "adj_key = \"spatial_connectivities\"\n",
    "cat_covariates_keys = [\"sample\"]\n",
    "gp_names_key = \"nichecompass_gp_names\"\n",
    "active_gp_names_key = \"nichecompass_active_gp_names\"\n",
    "gp_targets_mask_key = \"nichecompass_gp_targets\"\n",
    "gp_targets_categories_mask_key = \"nichecompass_gp_targets_categories\"\n",
    "gp_sources_mask_key = \"nichecompass_gp_sources\"\n",
    "gp_sources_categories_mask_key = \"nichecompass_gp_sources_categories\"\n",
    "latent_key = \"nichecompass_latent\"\n",
    "\n",
    "# Architecture\n",
    "cat_covariates_embeds_injection = [\"gene_expr_decoder\"]\n",
    "cat_covariates_embeds_nums = [len(reference_batches) + len(query_batches)] ## number samples\n",
    "cat_covariates_no_edges = [True]\n",
    "conv_layer_encoder = \"gatv2conv\" # change to \"gatv2conv\" if enough compute and memory\n",
    "active_gp_thresh_ratio = 0.01\n",
    "\n",
    "# Trainer\n",
    "n_epochs_all_gps = 25\n",
    "lr = 0.001\n",
    "lambda_edge_recon = 500000.\n",
    "lambda_gene_expr_recon = 300.\n",
    "lambda_l1_masked = 0. # increase if gene selection desired\n",
    "lambda_l1_addon = 100.\n",
    "edge_batch_size = 1024 # increase if more memory available\n",
    "n_sampled_neighbors = 4\n",
    "use_cuda_if_available = True\n",
    " \n",
    "\n",
    "### Analysis ###\n",
    "cell_type_key = \"Annotation\"\n",
    "latent_leiden_resolution = 1\n",
    "latent_cluster_key = f\"latent_leiden_{str(latent_leiden_resolution)}\"\n",
    "sample_key = \"sample\"\n",
    "spot_size = 250\n",
    "differential_gp_test_results_key = \"nichecompass_differential_gp_test_results\"\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Get time of notebook execution for timestamping saved artifacts\n",
    "now = datetime.now()\n",
    "current_timestamp = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "current_timestamp += dataset  ## Change this for your own project label\n",
    "current_timestamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80e39b0-25bc-4dd7-b91d-88b63bb531cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dab52c-8226-4186-abe6-80891f6bcedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dryrun=False\n",
    "def read_and_qc(sample_name, wtsi, path='rawdata.h5ad'):\n",
    "    \"\"\" This function reads anndata object.\n",
    "    It also calculates QC metrics. Modify this function if required by your workflow.\n",
    "    \"\"\"\n",
    "    print(path)\n",
    "    adata = sc.read_h5ad(path)\n",
    "\n",
    "    adata.uns['spatial'][sample_name] = adata.uns['spatial'].pop(list(adata.uns['spatial'])[0])\n",
    "    adata.obs['label'] = list(adata.uns['spatial'])[0]\n",
    "    adata.obs['WTSI_ID'] = wtsi\n",
    "\n",
    "    # fix TypeError when read in obsm\n",
    "    adata.obsm['spatial'] = adata.obsm['spatial'].astype(float)\n",
    "    # Calculate QC metrics\n",
    "    from scipy.sparse import csr_matrix\n",
    "    \n",
    "    sc.pp.calculate_qc_metrics(adata, inplace=True)\n",
    "    adata.var['MT'] = [gene.startswith('MT-') for gene in adata.var_names]\n",
    "    # adata.obs['mt_frac'] = adata[:, adata.var['MT'].tolist()].X.sum(1).A.squeeze()/adata.obs['total_counts']\n",
    "    \n",
    "    # add sample name to obs names\n",
    "    # adata.obs[\"sample\"] = [str(i) for i in adata.obs['sample']]\n",
    "    # adata.obs_names = adata.obs[\"sample\"] \\\n",
    "    #                       + '_' + adata.obs_names\n",
    "    adata.obs.index.name = 'spot_id'\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097967b9-c8b7-4ea1-95ca-22ec796912d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "ga_data_folder_path = f\"{handle}/data/gene_annotations\"\n",
    "gp_data_folder_path = f\"{handle}/data/gene_programs\"\n",
    "so_data_folder_path = f\"{handle}/data/spatial_omics\"\n",
    "omnipath_lr_network_file_path = f\"{gp_data_folder_path}/omnipath_lr_network.csv\"\n",
    "collectri_tf_network_file_path = f\"{gp_data_folder_path}/collectri_tf_network_{species}.csv\"\n",
    "nichenet_lr_network_file_path = f\"{gp_data_folder_path}/nichenet_lr_network_v2_{species}.csv\"\n",
    "nichenet_ligand_target_matrix_file_path = f\"{gp_data_folder_path}/nichenet_ligand_target_matrix_v2_{species}.csv\"\n",
    "mebocost_enzyme_sensor_interactions_folder_path = f\"{gp_data_folder_path}/metabolite_enzyme_sensor_gps\"\n",
    "gene_orthologs_mapping_file_path = f\"{ga_data_folder_path}/human_mouse_gene_orthologs.csv\"\n",
    "artifacts_folder_path = f\"{handle}/artifacts\"\n",
    "model_folder_path = f\"{artifacts_folder_path}/spatial_reference_mapping/{current_timestamp}/model\"\n",
    "figure_folder_path = f\"{artifacts_folder_path}/spatial_reference_mapping/{current_timestamp}/figures\"\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "if dryrun != True:\n",
    "    os.makedirs(ga_data_folder_path, exist_ok=True)\n",
    "    os.makedirs(gp_data_folder_path, exist_ok=True)\n",
    "    os.makedirs(model_folder_path, exist_ok=True)\n",
    "    os.makedirs(figure_folder_path, exist_ok=True)\n",
    "    os.makedirs(so_data_folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cee092-576d-49c7-9bd5-f253eb96a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract GPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7248515-078a-43e2-a77f-ae522eb070ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This part connects and retrieve information from database, so re-run if unfortunately the server is too busy and you get error\n",
    "\n",
    "\n",
    "import omnipath as op\n",
    "\n",
    "def extract_gp_dict_from_omnipath_lr_interactions(\n",
    "        species =  \"human\",\n",
    "        min_curation_effort: int=2,\n",
    "        load_from_disk: bool=False,\n",
    "        save_to_disk: bool=False,\n",
    "        lr_network_file_path: str=\"../data/gene_programs/\" \\\n",
    "                                            \"omnipath_lr_network.csv\",\n",
    "        gene_orthologs_mapping_file_path: str=\"../data/gene_\" \\\n",
    "                                                        \"annotations/human_\" \\\n",
    "                                                        \"mouse_gene_orthologs.csv\",\n",
    "        plot_gp_gene_count_distributions: bool=True,\n",
    "        gp_gene_count_distributions_save_path: str=None) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve 724 human ligand-receptor interactions from OmniPath and extract\n",
    "    them into a gene program dictionary. OmniPath is a database of molecular\n",
    "    biology prior knowledge that combines intercellular communication data from\n",
    "    many different resources (all resources for intercellular communication\n",
    "    included in OmniPath can be queried via\n",
    "    ´op.requests.Intercell.resources()´). If ´species´ is ´mouse´, orthologs\n",
    "    from human interactions are returned.\n",
    "\n",
    "    Parts of the implementation are inspired by \n",
    "    https://workflows.omnipathdb.org/intercell-networks-py.html (01.10.2022).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    species:\n",
    "        Species for which the gene programs will be extracted. The default is\n",
    "        human. Human genes are mapped to mouse orthologs using a mapping file.\n",
    "        NicheCompass contains a default mapping file stored under\n",
    "        \"<root>/data/gene_annotations/human_mouse_gene_orthologs.csv\", which was\n",
    "        created with Ensembl BioMart\n",
    "        (http://www.ensembl.org/info/data/biomart/index.html).\n",
    "    min_curation_effort: \n",
    "        Indicates how many times an interaction has to be described in a \n",
    "        paper and mentioned in a database to be included in the retrieval.\n",
    "    load_from_disk:\n",
    "        If ´True´, the OmniPath ligand receptor interactions will be loaded from\n",
    "        disk instead of from the OmniPath library.\n",
    "    save_to_disk:\n",
    "        If ´True´, the OmniPath ligand receptor interactions will additionally \n",
    "        be stored on disk. Only applies if ´load_from_disk´ is ´False´.\n",
    "    lr_network_file_path:\n",
    "        Path of the file where the OmniPath ligand receptor interactions will be\n",
    "        stored (if ´save_to_disk´ is ´True´) or loaded from (if ´load_from_disk´\n",
    "        is ´True´).\n",
    "    gene_orthologs_mapping_file_path:\n",
    "        Path of the file where the gene orthologs mapping is stored if species\n",
    "        is ´mouse´.\n",
    "    plot_gp_gene_count_distributions:\n",
    "        If ´True´, display the distribution of gene programs per number of\n",
    "        source and target genes.\n",
    "    gp_gene_count_distributions_save_path:\n",
    "        Path of the file where the gene program gene count distribution plot\n",
    "        will be saved if ´plot_gp_gene_count_distributions´ is ´True´.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    gp_dict:\n",
    "        Nested dictionary containing the OmniPath ligand-receptor interaction\n",
    "        gene programs with keys being gene program names and values being\n",
    "        dictionaries with keys ´sources´, ´targets´, ´sources_categories´, and\n",
    "        ´targets_categories´, where ´sources´ contains the OmniPath ligands,\n",
    "        ´targets´ contains the OmniPath receptors, ´sources_categories´ contains\n",
    "        the categories of the sources, and ´targets_categories´ contains\n",
    "        the categories of the targets.\n",
    "    \"\"\"\n",
    "    if not load_from_disk:\n",
    "        # Define intercell_network categories to be retrieved (see\n",
    "        # https://workflows.omnipathdb.org/intercell-networks-py.html,\n",
    "        # https://omnipath.readthedocs.io/en/latest/api/omnipath.interactions.import_intercell_network.html#omnipath.interactions.import_intercell_network)\n",
    "        intercell_df = op.interactions.import_intercell_network(\n",
    "            include=[\"omnipath\", \"pathwayextra\", \"ligrecextra\"])\n",
    "        lr_interaction_df = intercell_df[\n",
    "            (intercell_df[\"category_intercell_source\"] == \"ligand\")\n",
    "            & (intercell_df[\"category_intercell_target\"] == \"receptor\")]\n",
    "        if save_to_disk:\n",
    "            lr_interaction_df.to_csv(lr_network_file_path, index=False)\n",
    "    else:\n",
    "        lr_interaction_df = pd.read_csv(lr_network_file_path, index_col=0)\n",
    "\n",
    "    # Only keep curated interactions (see\n",
    "    # https://r.omnipathdb.org/reference/filter_intercell_network.html)\n",
    "    lr_interaction_df = lr_interaction_df[\n",
    "        lr_interaction_df[\"curation_effort\"] >= min_curation_effort]\n",
    "\n",
    "    # Group receptors by ligands\n",
    "    grouped_lr_interaction_df = lr_interaction_df.groupby(\n",
    "        \"genesymbol_intercell_source\")[\"genesymbol_intercell_target\"].agg(\n",
    "            list).reset_index()\n",
    "\n",
    "    # Resolve protein complexes into individual genes\n",
    "    def compute_elementwise_func(lst, func):\n",
    "        return [func(item) for item in lst]\n",
    "\n",
    "    def resolve_protein_complexes(x):\n",
    "        if not x:  # catches None, NaN, empty string\n",
    "            return []\n",
    "        if isinstance(x, float):  # just in case it's a NaN float\n",
    "            return []\n",
    "        if \"COMPLEX:\" not in x:\n",
    "            return [x]\n",
    "        else:\n",
    "            # Example: split out complexes if your format is like \"COMPLEX:A_B\"\n",
    "            return x.replace(\"COMPLEX:\", \"\").split(\"_\")\n",
    "\n",
    "    grouped_lr_interaction_df[\"sources\"] = grouped_lr_interaction_df[\n",
    "        \"genesymbol_intercell_source\"].apply(\n",
    "            lambda x: list(set(resolve_protein_complexes(x))))\n",
    "    \n",
    "    \n",
    "    \n",
    "    grouped_lr_interaction_df[\"sources_categories\"] = grouped_lr_interaction_df[\n",
    "        \"sources\"].apply(lambda x: [\"ligand\"] * len(x))\n",
    "    grouped_lr_interaction_df[\"targets\"] = grouped_lr_interaction_df[\n",
    "        \"genesymbol_intercell_target\"].apply(\n",
    "            lambda x: list(set([element for sublist in compute_elementwise_func(x, resolve_protein_complexes) for element in sublist])))\n",
    "    grouped_lr_interaction_df[\"targets_categories\"] = grouped_lr_interaction_df[\n",
    "        \"targets\"].apply(lambda x: [\"receptor\"] * len(x))\n",
    "    \n",
    "\n",
    "    #Extract gene programs and store in nested dict\n",
    "    gp_dict = {}\n",
    "    for _, row in grouped_lr_interaction_df.iterrows():\n",
    "        gp_dict[row[\"genesymbol_intercell_source\"] +\n",
    "                \"_ligand_receptor_GP\"] = {\n",
    "                    \"sources\": row[\"sources\"],\n",
    "                    \"targets\": row[\"targets\"],\n",
    "                    \"sources_categories\": row[\"sources_categories\"],\n",
    "                    \"targets_categories\": row[\"targets_categories\"]}\n",
    "        \n",
    "    if species == \"mouse\":\n",
    "        # Create mapping df to map from human genes to mouse orthologs\n",
    "        mapping_df = pd.read_csv(gene_orthologs_mapping_file_path)\n",
    "        grouped_mapping_df = mapping_df.groupby(\n",
    "            \"Gene name\")[\"Mouse gene name\"].agg(list).reset_index()\n",
    "        \n",
    "        # Map all genes in the gene programs to their orthologs from the mapping\n",
    "        # df or capitalize them if no orthologs are found (one human gene can\n",
    "        # have multiple mouse orthologs)\n",
    "        for _, gp in gp_dict.items():\n",
    "            gp[\"sources\"] = [element for nested_list_l1 in [\n",
    "                list_element for nested_list_l2 in [\n",
    "                    grouped_mapping_df[\n",
    "                        grouped_mapping_df[\"Gene name\"] == source][\n",
    "                            \"Mouse gene name\"].values.tolist() if\n",
    "                            source in grouped_mapping_df[\"Gene name\"].values else\n",
    "                            [[source.capitalize()]] for source in gp[\"sources\"]]\n",
    "                            for list_element in nested_list_l2]\n",
    "                            for element in nested_list_l1]\n",
    "            gp[\"targets\"] = [element for nested_list_l1 in [\n",
    "                list_element for nested_list_l2 in [\n",
    "                    grouped_mapping_df[\n",
    "                        grouped_mapping_df[\"Gene name\"] == target][\n",
    "                            \"Mouse gene name\"].values.tolist() if\n",
    "                            target in grouped_mapping_df[\"Gene name\"].values else\n",
    "                            [[target.capitalize()]] for target in gp[\"targets\"]]\n",
    "                            for list_element in nested_list_l2]\n",
    "                            for element in nested_list_l1]\n",
    "            gp[\"sources_categories\"] = [\"ligand\"] * len(gp[\"sources\"])\n",
    "            gp[\"targets_categories\"] = [\"receptor\"] * len(gp[\"targets\"])\n",
    "    \n",
    "    if plot_gp_gene_count_distributions:\n",
    "        create_gp_gene_count_distribution_plots(\n",
    "            gp_dict=gp_dict,\n",
    "            gp_plot_label=\"OmniPath\",\n",
    "            save_path=gp_gene_count_distributions_save_path)\n",
    "        \n",
    "    return gp_dict\n",
    "omnipath_gp_dict = extract_gp_dict_from_omnipath_lr_interactions(\n",
    "    species=\"human\",\n",
    "    min_curation_effort=2,\n",
    "    load_from_disk=False,\n",
    "    save_to_disk=True,\n",
    "    lr_network_file_path=omnipath_lr_network_file_path,\n",
    "    gene_orthologs_mapping_file_path=gene_orthologs_mapping_file_path,\n",
    "    plot_gp_gene_count_distributions=False,\n",
    "    gp_gene_count_distributions_save_path=f\"/omnipath_gp_gene_count_distributions.svg\")\n",
    "#omnipath_gp_dict.head(5)\n",
    "\n",
    "omnipath_gp_names = list(omnipath_gp_dict.keys())\n",
    "random.shuffle(omnipath_gp_names)\n",
    "omnipath_gp_name = omnipath_gp_names[0]\n",
    "print(f\"{omnipath_gp_name}: {omnipath_gp_dict[omnipath_gp_name]}\")\n",
    "\n",
    "nichenet_gp_dict = extract_gp_dict_from_nichenet_lrt_interactions(\n",
    "    species=species,\n",
    "    version=\"v2\",\n",
    "    keep_target_genes_ratio=1.,\n",
    "    max_n_target_genes_per_gp=250,\n",
    "    load_from_disk=False,\n",
    "    save_to_disk=True,\n",
    "    lr_network_file_path=nichenet_lr_network_file_path,\n",
    "    ligand_target_matrix_file_path=nichenet_ligand_target_matrix_file_path,\n",
    "    gene_orthologs_mapping_file_path=gene_orthologs_mapping_file_path,\n",
    "    plot_gp_gene_count_distributions=True)\n",
    "\n",
    "nichenet_gp_names = list(nichenet_gp_dict.keys())\n",
    "random.shuffle(nichenet_gp_names)\n",
    "nichenet_gp_name = nichenet_gp_names[0]\n",
    "print(f\"{nichenet_gp_name}: {nichenet_gp_dict[nichenet_gp_name]}\")\n",
    "\n",
    "mebocost_gp_dict = extract_gp_dict_from_mebocost_ms_interactions(\n",
    "    dir_path=mebocost_enzyme_sensor_interactions_folder_path,\n",
    "    species=species,\n",
    "    plot_gp_gene_count_distributions=True)\n",
    "\n",
    "mebocost_gp_names = list(mebocost_gp_dict.keys())\n",
    "random.shuffle(mebocost_gp_names)\n",
    "mebocost_gp_name = mebocost_gp_names[0]\n",
    "print(f\"{mebocost_gp_name}: {mebocost_gp_dict[mebocost_gp_name]}\")\n",
    "gp_dicts = [omnipath_gp_dict, nichenet_gp_dict, mebocost_gp_dict]\n",
    "combined_gp_dict = filter_and_combine_gp_dict_gps_v2(\n",
    "    gp_dicts,\n",
    "    verbose=True)\n",
    "\n",
    "print(f\"Number of gene programs after filtering and combining: \"\n",
    "      f\"{len(combined_gp_dict)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a35e087-0704-464a-885a-3869ce8ece79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8357060a-c7d9-4973-a83b-85e40daac4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### from jimmy lee \n",
    "def select_slide2(adata, s, s_col='sample'):\n",
    "    \"\"\" This function selects the data for one slide from the spatial anndata object.\n",
    "    :param adata: Anndata object with multiple spatial experiments\n",
    "    :param s: name of selected experiment\n",
    "    :param s_col: column in adata.obs listing experiment name for each location\n",
    "    \"\"\"\n",
    "    slide = adata[adata.obs[s_col].isin([s]), :]\n",
    "#     s_keys = list(slide.uns['spatial'].keys())\n",
    "#     s_spatial = np.array(s_keys)[[s in k for k in s_keys]][0]\n",
    "#     slide.uns['spatial'] = {s_spatial: slide.uns['spatial'][s_spatial]}\n",
    "    return slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35af7aa9-7d37-4653-aec0-0387a46b2c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for batch in reference_batches:\n",
    "#     print(f\"Processing batch {batch}...\")\n",
    "#     print(\"Loading data...\")\n",
    "#     adata_batch = select_slide2(adata_vis, batch)\n",
    "\n",
    "\n",
    "\n",
    "# adata_batch_list = []\n",
    "# print(\"Processing reference batches...\")\n",
    "# for batch in reference_batches:\n",
    "#     print(f\"Processing batch {batch}...\")\n",
    "#     print(\"Loading data...\")\n",
    "#     adata_batch = select_slide2(adata_vis, batch)\n",
    "#     print(f\"Size {adata_batch.shape}\")\n",
    "#     print(\"Computing spatial neighborhood graph...\\n\")\n",
    "#     # Compute (separate) spatial neighborhood graphs\n",
    "#     logging.info(\"sq.gr.spatial_neighbors\")\n",
    "#     #try:\n",
    "#     sq.gr.spatial_neighbors(adata_batch,\n",
    "#                                 coord_type=\"generic\",\n",
    "#                                 spatial_key=spatial_key,\n",
    "#                                 n_neighs=n_neighbors)\n",
    "#     #except:\n",
    "#     #    continue\n",
    "#     print(f\"Spatial neighbours done ## {adata_batch.shape}\")\n",
    "\n",
    "#     # Make adjacency matrix symmetric\n",
    "#     adata_batch.obsp[adj_key] = (\n",
    "#         adata_batch.obsp[adj_key].maximum(\n",
    "#             adata_batch.obsp[adj_key].T))\n",
    "#     adata_batch_list.append(adata_batch)\n",
    "# print(\"List made: ...\")\n",
    "# for x in adata_batch_list:\n",
    "#     print(x.shape)\n",
    "# adata_reference = ad.concat(adata_batch_list, join=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799000ab-c335-4553-a5b2-ca25b2a08088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combine spatial neighborhood graphs as disconnected components\n",
    "# batch_connectivities = []\n",
    "# len_before_batch = 0\n",
    "# for i in range(len(adata_batch_list)):\n",
    "#     if i == 0: # first batch\n",
    "#         after_batch_connectivities_extension = sp.csr_matrix(\n",
    "#             (adata_batch_list[0].shape[0],\n",
    "#             (adata_reference.shape[0] -\n",
    "#             adata_batch_list[0].shape[0])))\n",
    "#         batch_connectivities.append(sp.hstack(\n",
    "#             (adata_batch_list[0].obsp[adj_key],\n",
    "#             after_batch_connectivities_extension)))\n",
    "#     elif i == (len(adata_batch_list) - 1): # last batch\n",
    "#         before_batch_connectivities_extension = sp.csr_matrix(\n",
    "#             (adata_batch_list[i].shape[0],\n",
    "#             (adata_reference.shape[0] -\n",
    "#             adata_batch_list[i].shape[0])))\n",
    "#         batch_connectivities.append(sp.hstack(\n",
    "#             (before_batch_connectivities_extension,\n",
    "#             adata_batch_list[i].obsp[adj_key])))\n",
    "#     else: # middle batches\n",
    "#         before_batch_connectivities_extension = sp.csr_matrix(\n",
    "#             (adata_batch_list[i].shape[0], len_before_batch))\n",
    "#         after_batch_connectivities_extension = sp.csr_matrix(\n",
    "#             (adata_batch_list[i].shape[0],\n",
    "#             (adata_reference.shape[0] -\n",
    "#             adata_batch_list[i].shape[0] -\n",
    "#             len_before_batch)))\n",
    "#         batch_connectivities.append(sp.hstack(\n",
    "#             (before_batch_connectivities_extension,\n",
    "#             adata_batch_list[i].obsp[adj_key],\n",
    "#             after_batch_connectivities_extension)))\n",
    "#     len_before_batch += adata_batch_list[i].shape[0]\n",
    "# adata_reference.obsp[adj_key] = sp.vstack(batch_connectivities)\n",
    "# adata_reference.obs[mapping_entity_key] = \"reference\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Filter spatially variable genes\n",
    "\n",
    "# logging.info(\"sq.gr.spatial_autocorr\")\n",
    "# sq.gr.spatial_autocorr(adata_reference, mode=\"moran\", genes=adata_vis.var_names)\n",
    "# sv_genes = adata_reference.uns[\"moranI\"].index[:n_svg].tolist()\n",
    "# adata_reference.var[\"spatially_variable\"] = adata_reference.var_names.isin(sv_genes)\n",
    "\n",
    "# adata_reference.var[\"keep_gene\"] = adata_reference.var[\"spatially_variable\"]\n",
    "# adata_reference = adata_reference[:, adata_reference.var[\"keep_gene\"] == True]\n",
    "# print(f\"Keeping {len(adata_reference.var_names)} spatially variable, highly \"\n",
    "#       \"variable or gene program relevant genes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b995c7c6-151a-40b7-87b8-b79f02b9e5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add the GP dictionary as binary masks to the adata\n",
    "# logging.info(\"add_gps_from_gp_dict_to_adata\")\n",
    "# add_gps_from_gp_dict_to_adata(\n",
    "#     gp_dict=combined_gp_dict,\n",
    "#     adata=adata_reference,\n",
    "#     gp_targets_mask_key=gp_targets_mask_key,\n",
    "#     gp_targets_categories_mask_key=gp_targets_categories_mask_key,\n",
    "#     gp_sources_mask_key=gp_sources_mask_key,\n",
    "#     gp_sources_categories_mask_key=gp_sources_categories_mask_key,\n",
    "#     gp_names_key=gp_names_key,\n",
    "#     min_genes_per_gp=2,\n",
    "#     min_source_genes_per_gp=1,\n",
    "#     min_target_genes_per_gp=1,\n",
    "#     max_genes_per_gp=None,\n",
    "#     max_source_genes_per_gp=None,\n",
    "#     max_target_genes_per_gp=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d3c1cf-0a85-4219-a855-631a34ea8072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cast_adata_to_float32(adata, counts_key=\"counts\"):\n",
    "#     adata.X = adata.X.astype(\"float32\")                           # keeps sparse\n",
    "#     if counts_key in adata.layers:                                # fix the layer the model uses\n",
    "#         adata.layers[counts_key] = adata.layers[counts_key].astype(\"float32\")\n",
    "#     for lyr in adata.layers:                                      # belt-and-braces\n",
    "#         adata.layers[lyr] = adata.layers[lyr].astype(\"float32\")\n",
    "#     return adata\n",
    "# adata_reference = cast_adata_to_float32(adata_reference, counts_key=counts_key)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aade4e-c40e-42bd-9255-43ecab7a8b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize model + train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b994136-d676-410c-9c5a-8f8d4d0838fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Initialize model\n",
    "# logging.info(\"NicheCompass\")\n",
    "# model = NicheCompass(adata_reference,\n",
    "#                      counts_key=counts_key,\n",
    "#                      adj_key=adj_key,\n",
    "#                      cat_covariates_embeds_injection=cat_covariates_embeds_injection,\n",
    "#                      cat_covariates_keys=cat_covariates_keys,\n",
    "#                      cat_covariates_no_edges=cat_covariates_no_edges,\n",
    "#                      cat_covariates_embeds_nums=cat_covariates_embeds_nums,\n",
    "#                      gp_names_key=gp_names_key,\n",
    "#                      active_gp_names_key=active_gp_names_key,\n",
    "#                      gp_targets_mask_key=gp_targets_mask_key,\n",
    "#                      gp_targets_categories_mask_key=gp_targets_categories_mask_key,\n",
    "#                      gp_sources_mask_key=gp_sources_mask_key,\n",
    "#                      gp_sources_categories_mask_key=gp_sources_categories_mask_key,\n",
    "#                      latent_key=latent_key,\n",
    "#                      conv_layer_encoder=conv_layer_encoder,\n",
    "#                      active_gp_thresh_ratio=active_gp_thresh_ratio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeb0b81-b0e3-4874-bca7-4d73e8777173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train model\n",
    "# logging.info(\"model.train\")\n",
    "# model.train(n_epochs=n_epochs,\n",
    "#             n_epochs_all_gps=n_epochs_all_gps,\n",
    "#             lr=lr,\n",
    "#             lambda_edge_recon=lambda_edge_recon,\n",
    "#             lambda_gene_expr_recon=lambda_gene_expr_recon,\n",
    "#             lambda_l1_masked=lambda_l1_masked,\n",
    "#             edge_batch_size=edge_batch_size,\n",
    "#             n_sampled_neighbors=n_sampled_neighbors,\n",
    "#             use_cuda_if_available=use_cuda_if_available,\n",
    "#             verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e95c26a-11bf-42e0-8600-b0a4d4665a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.info(\"sc.pp.neighbors\")\n",
    "\n",
    "# sc.pp.neighbors(model.adata,\n",
    "#                 use_rep=latent_key,\n",
    "#                 key_added=latent_key)\n",
    "\n",
    "# # Compute UMAP embedding\n",
    "# logging.info(\"sc.tl.umap\")\n",
    "# sc.tl.umap(model.adata,\n",
    "#            neighbors_key=latent_key,\n",
    "#           min_dist=0.1 \n",
    "#           )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a255d33e-ae30-4b37-b92b-01a45a99cb26",
   "metadata": {},
   "source": [
    "# save reference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c4ad58-a2ac-4eb1-b483-8da12c391cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.tl.leiden(model.adata,\n",
    "#                 resolution=latent_leiden_resolution,\n",
    "#                 key_added=latent_cluster_key,\n",
    "#                 neighbors_key=latent_key)\n",
    "\n",
    "\n",
    "\n",
    "# # Save trained model\n",
    "# logging.info(\"model.save\")\n",
    "# model.save(dir_path=f\"{model_folder_path}/reference\",\n",
    "#            overwrite=True,\n",
    "#            save_adata=True,\n",
    "#            adata_file_name=\"adata.h5ad\")\n",
    "\n",
    "# logging.info(\"reference model saved!\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d855c0af-d5ab-463c-bd13-d4e254b58db1",
   "metadata": {},
   "source": [
    "# Load reference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f3a9646-3303-460c-ba1e-2685d70f0ac9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnichecompass\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NicheCompass\n\u001b[32m      3\u001b[39m model_path = \u001b[33m\"\u001b[39m\u001b[33m/lustre/scratch124/cellgen/haniffa/projects/developmental_fibroblasts/nobackup_output/nichecompasss/nichecompass/artifacts/spatial_reference_mapping/20250909_114615XeniumBEACON_2000svg_n8_REFQ_presept/model/reference\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m model = NicheCompass.load(dir_path=model_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/software/cellgen/team298/ls34/nichecompass3/lib/python3.11/site-packages/nichecompass/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetadata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data, models, modules, nn, train, utils\n\u001b[32m      5\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodules\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mnn\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mutils\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      7\u001b[39m __version__ = version(\u001b[33m\"\u001b[39m\u001b[33mnichecompass\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/software/cellgen/team298/ls34/nichecompass3/lib/python3.11/site-packages/nichecompass/data/__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataloaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m initialize_dataloaders\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataprocessors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (edge_level_split,\n\u001b[32m      3\u001b[39m                              node_level_split_mask,\n\u001b[32m      4\u001b[39m                              prepare_data)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatareaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_spatial_adata_from_csv\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SpatialAnnTorchDataset\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/software/cellgen/team298/ls34/nichecompass3/lib/python3.11/site-packages/nichecompass/data/dataprocessors.py:14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch_geometric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomNodeSplit, RandomLinkSplit\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch_geometric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m add_self_loops, remove_self_loops\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SpatialAnnTorchDataset\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34medge_level_split\u001b[39m(data: Data,\n\u001b[32m     18\u001b[39m                      edge_label_adj: Optional[sp.csr_matrix],\n\u001b[32m     19\u001b[39m                      val_ratio: \u001b[38;5;28mfloat\u001b[39m=\u001b[32m0.1\u001b[39m,\n\u001b[32m     20\u001b[39m                      test_ratio: \u001b[38;5;28mfloat\u001b[39m=\u001b[32m0.\u001b[39m,\n\u001b[32m     21\u001b[39m                      is_undirected: \u001b[38;5;28mbool\u001b[39m=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     22\u001b[39m                      neg_sampling_ratio: \u001b[38;5;28mfloat\u001b[39m=\u001b[32m0.\u001b[39m) -> Tuple[Data, Data, Data]:\n\u001b[32m     23\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[33;03m    Split a PyG Data object into training, validation and test PyG Data objects \u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[33;03m    using an edge-level split. The training split does not include edges in the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     60\u001b[39m \u001b[33;03m        Test PyG Data object.\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/software/cellgen/team298/ls34/nichecompass3/lib/python3.11/site-packages/nichecompass/data/datasets.py:13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01manndata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AnnData\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch_geometric\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m add_self_loops, remove_self_loops\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m encode_labels, sparse_mx_to_sparse_tensor\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mSpatialAnnTorchDataset\u001b[39;00m():\n\u001b[32m     17\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[33;03m    Spatially annotated torch dataset class to extract node features, node \u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[33;03m    labels, adjacency matrix and edge indices in a standardized format from an \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     43\u001b[39m \u001b[33;03m        Keys under which the categorical covariates are stored in ´adata.obs´.\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/software/cellgen/team298/ls34/nichecompass3/lib/python3.11/site-packages/nichecompass/data/utils.py:9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m csr_matrix\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch_sparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparseTensor\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mencode_labels\u001b[39m(adata: ad.AnnData,\n\u001b[32m     13\u001b[39m                   label_encoder: \u001b[38;5;28mdict\u001b[39m,\n\u001b[32m     14\u001b[39m                   label_key=\u001b[33m\"\u001b[39m\u001b[33mstr\u001b[39m\u001b[33m\"\u001b[39m) -> np.ndarray:\n\u001b[32m     15\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03m    Encode labels from an `adata` object stored in `adata.obs` to integers.\u001b[39;00m\n\u001b[32m     17\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     34\u001b[39m \u001b[33;03m        Integer-encoded labels.\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch_sparse'"
     ]
    }
   ],
   "source": [
    "# from nichecompass.models import NicheCompass\n",
    "\n",
    "# model_path = \"/lustre/scratch124/cellgen/haniffa/projects/developmental_fibroblasts/nobackup_output/nichecompasss/nichecompass/artifacts/spatial_reference_mapping/20250909_114615XeniumBEACON_2000svg_n8_REFQ_presept/model/reference\"\n",
    "\n",
    "# model = NicheCompass.load(dir_path=model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6b31b0-d3e8-41e1-acd8-de759a6ab267",
   "metadata": {},
   "source": [
    "# process query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f288a2fb-aca3-4c9d-84c6-5daff265bb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_batch_list = []\n",
    "print(\"Processing query batches...\")\n",
    "# for batch in query_batches:\n",
    "#     print(f\"Processing batch {batch}...\")\n",
    "#     print(\"Loading data...\")\n",
    "#     adata_batch = sc.read_h5ad(\n",
    "#         f\"{so_data_folder_path}/{dataset}_{batch}.h5ad\")\n",
    "for batch in query_batches:\n",
    "    print(f\"Processing batch {batch}...\")\n",
    "    print(\"Loading data...\")\n",
    "    adata_batch = select_slide2(adata_vis, batch)\n",
    "    print(\"Computing spatial neighborhood graph...\\n\")\n",
    "    # Compute (separate) spatial neighborhood graphs\n",
    "    sq.gr.spatial_neighbors(adata_batch,\n",
    "                            coord_type=\"generic\",\n",
    "                            spatial_key=spatial_key,\n",
    "                            n_neighs=n_neighbors)\n",
    "    \n",
    "    # Make adjacency matrix symmetric\n",
    "    adata_batch.obsp[adj_key] = (\n",
    "        adata_batch.obsp[adj_key].maximum(\n",
    "            adata_batch.obsp[adj_key].T))\n",
    "    adata_batch_list.append(adata_batch)\n",
    "adata_query = ad.concat(adata_batch_list, join=\"inner\")\n",
    "adata_query.var[\"spatially_variable\"] = adata_query.var_names.isin(sv_genes)\n",
    "adata_query.var[\"keep_gene\"] = adata_query.var[\"spatially_variable\"]\n",
    "adata_query = adata_query[:, adata_query.var[\"keep_gene\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6250aa-ad3d-40aa-ae63-07c1d31d6ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(adata_batch_list)):\n",
    "    if i == 0: # first batch\n",
    "        after_batch_connectivities_extension = sp.csr_matrix(\n",
    "            (adata_batch_list[0].shape[0],\n",
    "            (adata_query.shape[0] -\n",
    "            adata_batch_list[0].shape[0])))\n",
    "        batch_connectivities.append(sp.hstack(\n",
    "            (adata_batch_list[0].obsp[adj_key],\n",
    "            after_batch_connectivities_extension)))\n",
    "    elif i == (len(adata_batch_list) - 1): # last batch\n",
    "        before_batch_connectivities_extension = sp.csr_matrix(\n",
    "            (adata_batch_list[i].shape[0],\n",
    "            (adata_query.shape[0] -\n",
    "            adata_batch_list[i].shape[0])))\n",
    "        batch_connectivities.append(sp.hstack(\n",
    "            (before_batch_connectivities_extension,\n",
    "            adata_batch_list[i].obsp[adj_key])))\n",
    "    else: # middle batches\n",
    "        before_batch_connectivities_extension = sp.csr_matrix(\n",
    "            (adata_batch_list[i].shape[0], len_before_batch))\n",
    "        after_batch_connectivities_extension = sp.csr_matrix(\n",
    "            (adata_batch_list[i].shape[0],\n",
    "            (adata_query.shape[0] -\n",
    "            adata_batch_list[i].shape[0] -\n",
    "            len_before_batch)))\n",
    "        batch_connectivities.append(sp.hstack(\n",
    "            (before_batch_connectivities_extension,\n",
    "            adata_batch_list[i].obsp[adj_key],\n",
    "            after_batch_connectivities_extension)))\n",
    "    len_before_batch += adata_batch_list[i].shape[0]\n",
    "adata_query.obsp[adj_key] = sp.vstack(batch_connectivities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ad65ec-b410-4a86-9f62-2d41e9a06a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine spatial neighborhood graphs as disconnected components\n",
    "batch_connectivities = []\n",
    "len_before_batch = 0\n",
    "\n",
    "adata_query.obs[mapping_entity_key] = \"query\"\n",
    "\n",
    "# Add the GP dictionary as binary masks to the adata\n",
    "add_gps_from_gp_dict_to_adata(\n",
    "    gp_dict=combined_gp_dict,\n",
    "    adata=adata_query,\n",
    "    gp_targets_mask_key=gp_targets_mask_key,\n",
    "    gp_targets_categories_mask_key=gp_targets_categories_mask_key,\n",
    "    gp_sources_mask_key=gp_sources_mask_key,\n",
    "    gp_sources_categories_mask_key=gp_sources_categories_mask_key,\n",
    "    gp_names_key=gp_names_key,\n",
    "    min_genes_per_gp=2,\n",
    "    min_source_genes_per_gp=1,\n",
    "    min_target_genes_per_gp=1,\n",
    "    max_genes_per_gp=None,\n",
    "    max_source_genes_per_gp=None,\n",
    "    max_target_genes_per_gp=None)\n",
    "\n",
    "logging.info(\"query model saved!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf2fb4d-2c5d-4988-9609-63f19b5dc74e",
   "metadata": {},
   "source": [
    "# ref query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b79be0e-d1ca-4fb8-b887-ba0bfc86cb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_timestamp = current_timestamp # uncomment if you trained the model in this notebook\n",
    "model_folder_path = f\"{artifacts_folder_path}/spatial_reference_mapping/{load_timestamp}/model\"\n",
    "\n",
    "adata_query = cast_adata_to_float32(adata_query, counts_key=counts_key)\n",
    "\n",
    "# Loading reference model with query data\n",
    "print(\"Retrieving reference model...\")\n",
    "model = NicheCompass.load(\n",
    "    dir_path=f\"{model_folder_path}/reference\",\n",
    "    adata=adata_query,\n",
    "    adata_file_name=\"adata.h5ad\",\n",
    "    gp_names_key=gp_names_key,\n",
    "    unfreeze_all_weights=False,\n",
    "    unfreeze_cat_covariates_embedder_weights=True)\n",
    "adata_reference = model.adata  # the adata you saved\n",
    "\n",
    "\n",
    "# Train model\n",
    "model.train(n_epochs=n_epochs,\n",
    "            n_epochs_all_gps=n_epochs_all_gps,\n",
    "            lr=lr,\n",
    "            lambda_edge_recon=lambda_edge_recon,\n",
    "            lambda_gene_expr_recon=lambda_gene_expr_recon,\n",
    "            lambda_l1_masked=lambda_l1_masked,\n",
    "            edge_batch_size=edge_batch_size,\n",
    "            n_sampled_neighbors=n_sampled_neighbors,\n",
    "            use_cuda_if_available=use_cuda_if_available)\n",
    "\n",
    "\n",
    "# Save trained model\n",
    "model.save(dir_path=f\"{model_folder_path}/query\",\n",
    "           overwrite=True,\n",
    "           save_adata=True,\n",
    "           adata_file_name=\"adata.h5ad\")\n",
    "\n",
    "logging.info(\"final model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5220c1-8356-4915-904d-c80d7fd46371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrate reference and query data\n",
    "adata_batch_list = [adata_reference, adata_query]\n",
    "adata_reference_query = ad.concat(adata_batch_list, join=\"inner\")\n",
    "adata_reference_query.var[\"spatially_variable\"] = adata_reference_query.var_names.isin(sv_genes)\n",
    "adata_reference_query.var[\"keep_gene\"] = adata_reference_query.var[\"spatially_variable\"]\n",
    "adata_reference_query = adata_reference_query[:, adata_reference_query.var[\"keep_gene\"] == True]\n",
    "logging.info(\"final model saved! \" )\n",
    "print(adata_reference_query.shape)\n",
    "\n",
    "# Combine spatial neighborhood graphs as disconnected components\n",
    "batch_connectivities = []\n",
    "len_before_batch = 0\n",
    "for i in range(len(adata_batch_list)):\n",
    "    if i == 0: # first batch\n",
    "        after_batch_connectivities_extension = sp.csr_matrix(\n",
    "            (adata_batch_list[0].shape[0],\n",
    "            (adata_reference_query.shape[0] -\n",
    "            adata_batch_list[0].shape[0])))\n",
    "        batch_connectivities.append(sp.hstack(\n",
    "            (adata_batch_list[0].obsp[adj_key],\n",
    "            after_batch_connectivities_extension)))\n",
    "    elif i == (len(adata_batch_list) - 1): # last batch\n",
    "        before_batch_connectivities_extension = sp.csr_matrix(\n",
    "            (adata_batch_list[i].shape[0],\n",
    "            (adata_reference_query.shape[0] -\n",
    "            adata_batch_list[i].shape[0])))\n",
    "        batch_connectivities.append(sp.hstack(\n",
    "            (before_batch_connectivities_extension,\n",
    "            adata_batch_list[i].obsp[adj_key])))\n",
    "    else: # middle batches\n",
    "        before_batch_connectivities_extension = sp.csr_matrix(\n",
    "            (adata_batch_list[i].shape[0], len_before_batch))\n",
    "        after_batch_connectivities_extension = sp.csr_matrix(\n",
    "            (adata_batch_list[i].shape[0],\n",
    "            (adata_reference_query.shape[0] -\n",
    "            adata_batch_list[i].shape[0] -\n",
    "            len_before_batch)))\n",
    "        batch_connectivities.append(sp.hstack(\n",
    "            (before_batch_connectivities_extension,\n",
    "            adata_batch_list[i].obsp[adj_key],\n",
    "            after_batch_connectivities_extension)))\n",
    "    len_before_batch += adata_batch_list[i].shape[0]\n",
    "adata_reference_query.obsp[adj_key] = sp.vstack(batch_connectivities)\n",
    "\n",
    "\n",
    "\n",
    "logging.info(\"integrated!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88cd5ec-2e46-4fcf-a6ae-90bb901fd5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the GP dictionary as binary masks to the adata\n",
    "add_gps_from_gp_dict_to_adata(\n",
    "    gp_dict=combined_gp_dict,\n",
    "    adata=adata_reference_query,\n",
    "    gp_targets_mask_key=gp_targets_mask_key,\n",
    "    gp_targets_categories_mask_key=gp_targets_categories_mask_key,\n",
    "    gp_sources_mask_key=gp_sources_mask_key,\n",
    "    gp_sources_categories_mask_key=gp_sources_categories_mask_key,\n",
    "    gp_names_key=gp_names_key,\n",
    "    min_genes_per_gp=2,\n",
    "    min_source_genes_per_gp=1,\n",
    "    min_target_genes_per_gp=1,\n",
    "    max_genes_per_gp=None,\n",
    "    max_source_genes_per_gp=None,\n",
    "    max_target_genes_per_gp=None)\n",
    "\n",
    "\n",
    "# Load query model with the integrated data\n",
    "print(\"Retrieving query model...\")\n",
    "model = NicheCompass.load(\n",
    "    dir_path=f\"{model_folder_path}/query\",\n",
    "    adata=adata_reference_query,\n",
    "    adata_file_name=\"adata.h5ad\",\n",
    "    gp_names_key=gp_names_key)\n",
    "\n",
    "\n",
    "print(\"Computing reference query latent GP space...\")\n",
    "model.adata.obsm[latent_key], _ = model.get_latent_representation(\n",
    "   adata=model.adata,\n",
    "   counts_key=counts_key,\n",
    "   adj_key=adj_key,\n",
    "   cat_covariates_keys=cat_covariates_keys,\n",
    "   only_active_gps=True,\n",
    "   return_mu_std=True,\n",
    "   node_batch_size=model.node_batch_size_)\n",
    "\n",
    "print(\"Computing active GPs...\")\n",
    "model.adata.uns[model.active_gp_names_key_] = model.get_active_gps()\n",
    "\n",
    "\n",
    "# Compute latent neighbor graph\n",
    "sc.pp.neighbors(model.adata,\n",
    "                use_rep=latent_key,\n",
    "                key_added=latent_key)\n",
    "\n",
    "# Compute UMAP embedding\n",
    "sc.tl.umap(model.adata,\n",
    "           neighbors_key=latent_key)\n",
    "\n",
    "\n",
    "# Save model\n",
    "model.save(dir_path=f\"{model_folder_path}/reference_query\",\n",
    "           overwrite=True,\n",
    "           save_adata=True,\n",
    "           adata_file_name=\"adata.h5ad\")\n",
    "print(\"final model saved!\")\n",
    " \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da191332-1c7f-4f84-9bde-2d19d2f2866c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9312622-9ac2-4789-aa8b-f323a1c2f1ec",
   "metadata": {},
   "source": [
    "# Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c38e902-a3ec-4140-a1f8-27c54132c62a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adata.h5ad.mindistumap.filtered.clustered4_coredata',\n",
       " 'adata_final.h5ad',\n",
       " 'attr.pkl',\n",
       " 'adata.h5ad.mindistumap.filtered',\n",
       " 'adata.h5ad',\n",
       " 'var_names.csv',\n",
       " 'adata.h5ad.mindistumap.filtered.clustered3',\n",
       " 'adata.h5ad.mindistumap.filtered.clustered',\n",
       " 'adata.h5ad.mindistumap.filtered.clustered4',\n",
       " 'adata.h5ad.mindistumap.filtered.clustered2',\n",
       " 'adata.h5ad.mindistumap',\n",
       " 'model_params.pt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "OUTPUT = \"/lustre/scratch124/cellgen/haniffa/projects/developmental_fibroblasts/nobackup_output/nichecompasss/nichecompass/artifacts/spatial_reference_mapping/20250909_114615XeniumBEACON_2000svg_n8_REFQ_presept/model/reference_query/\"\n",
    "os.listdir(OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04d50a3-8fae-4a7e-b227-2bbc278adbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_final = sc.read_h5ad(OUTPUT + \"adata.h5ad\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3436f6d9-c21d-40b5-b705-da33d8493aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37c5241-dc40-4001-8821-07df6bdbc229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a382dd-ce99-4b83-b950-307e43923587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7be1bec-ced0-442e-903f-4fbe9affae40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad28035a-96e5-405b-801e-a27fa0608ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918495a9-7655-416e-ab7a-22f14650d0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nichecompass3",
   "language": "python",
   "name": "nichecompass3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
